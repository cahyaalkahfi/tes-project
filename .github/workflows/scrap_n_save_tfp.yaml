name: scrap and save TFP to PGSQL

on:
  schedule:
    # - cron: '0 */2 * * *'  # every 2 hour for testing.
    - cron: '0 3 * *'  # once a day at 01 AM UTC (08:00 WIB).

jobs:
  scrap-n-save:
    runs-on: ubuntu-latest
    env:
      DATABASE_URL: ${{ secrets.DATABASE_URL }}
      TWITTER_CONSUMER_API_KEY: ${{ secrets.TWITTER_CONSUMER_API_KEY }}
      TWITTER_CONSUMER_API_SECRET: ${{ secrets.TWITTER_CONSUMER_API_SECRET }}
      ACCESS_TOKEN: ${{ secrets.ACCESS_TOKEN }}
      ACCESS_TOKEN_SECRET: ${{ secrets.ACCESS_TOKEN_SECRET }}
    steps:
     - uses: actions/checkout@v3
     - uses: actions/setup-python@v3
       with:
         python-version: '3.10' 
     - run: |
        python -m pip install --upgrade pip
        pip install pandas bs4 psycopg2
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
     - run: python3 scrap_n_save_tfp.py
     # Add new files in data folder, commit along with other modified files, push
     - name: Commit and push if it changed
       run: |-
          git config user.name "Automated"
          git config user.email "actions@users.noreply.github.com"
          git add -A
          timestamp=$(date -u)
          git commit -m "Latest data: ${timestamp}" || exit 0
          git push
