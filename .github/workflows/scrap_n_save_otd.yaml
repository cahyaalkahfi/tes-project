name: scrap and save to postgresql

on:
  schedule:
    - cron: '5 * * * *'  # every 5 minutes for testing.
    #- cron: '0 1 * *'  # once a day at 01 AM UTC (08:00 WIB).

jobs:
  scrap-n-save:
    runs-on: ubuntu-latest
    env:
      DATABASE_URL: ${{ secrets.DATABASE_URL }}
      TWITTER_CONSUMER_API_KEY: ${{ secrets.TWITTER_CONSUMER_API_KEY }}
      TWITTER_CONSUMER_API_SECRET: ${{ secrets.TWITTER_CONSUMER_API_SECRET }}
      ACCESS_TOKEN: ${{ secrets.ACCESS_TOKEN }}
      ACCESS_TOKEN_SECRET: ${{ secrets.ACCESS_TOKEN_SECRET }}
    steps:
     - uses: actions/checkout@v3
     - uses: actions/setup-python@v4
       with:
         python-version: '3.10' 
         cache: 'pip'
     - run: pip install pandas bs4 psycopg2
     - run: python3 scrap_n_save_otd.py
     # Add new files in data folder, commit along with other modified files, push
     - name: Commit and push if it changed
       run: |-
          git config user.name "Automated"
          git config user.email "actions@users.noreply.github.com"
          git add -A
          timestamp=$(date -u)
          git commit -m "Latest data: ${timestamp}" || exit 0
          git push
